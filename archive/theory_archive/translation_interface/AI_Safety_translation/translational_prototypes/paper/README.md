# Calibrated Transparency: A Mechanistic, Adversarial-Robust, and Policy-Aligned Safety Architecture

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17336217.svg)](https://doi.org/10.5281/zenodo.17336217)

## Overview

**Calibrated Transparency (CT)** is a formal AI safety framework integrating recursive value learning, adversarial-robust verification, and cryptographic auditability.  
It provides **mechanistically grounded assurance** for safe AI governance through measurable transparency and risk composition.

This repository contains the full research text and supplementary materials associated with the publication archived on Zenodo.

- ğŸ“˜ **Main Paper:** `CT_main.pdf`
- ğŸ“— **Supplementary Appendices:** `CT_supplementary.pdf`
- ğŸ§¾ **Zenodo DOI:** [10.5281/zenodo.17336217](https://doi.org/10.5281/zenodo.17336217)

---

## Abstract

I propose **Calibrated Transparency (CT)**, a formal framework that integrates recursive value learning, adversarial-robust verification, and cryptographic auditability to operationalize AI safety governance. Unlike descriptive transparency, CT establishes **causal pathways** from calibration mechanisms to safety guarantees through:

1. State-consistent Lyapunov verification with runtime monitoring  
2. Robustness against metric gaming and deceptive alignment with measurable detection bounds  
3. **Operationally defined metrics** with reproducible protocols  
4. Policy-aligned implementation mappings  

CT synthesizes 2020â€“2025 research across preference learning (Kim et al., 2025), Lyapunov and barrier-certificate verification (Henzinger et al., 2025), cryptographic auditing (Balan et al., 2025), and governance frameworks (NIST AI RMF, EU AI Act, ISO/IEC 42001).

---

## Repository Structure

```
â”œâ”€â”€ CT_main.pdf              # Main paper
â”œâ”€â”€ CT_supplementary.pdf     # Full appendices (Aâ€“H)
â”œâ”€â”€ zenodo_metadata.json     # Zenodo-compatible metadata file
â””â”€â”€ README.md                # This file
```

---

## Citation

If you use this work, please cite as:

```bibtex
@article{Sasano2025_CT,
  author    = {Kiyoshi Sasano},
  title     = {Calibrated Transparency: A Mechanistic, Adversarial-Robust, and Policy-Aligned Safety Architecture},
  year      = {2025},
  doi       = {10.5281/zenodo.17336217},
  publisher = {Zenodo},
  url       = {https://doi.org/10.5281/zenodo.17336217}
}
```

---

## License

This work is licensed under the **Creative Commons Attribution 4.0 International License (CC BY 4.0)**.  
You are free to share and adapt the material with appropriate attribution.

---

## Related Repository

ğŸ”— [GitHub Repository](https://github.com/kiyoshisasano-DeepZenSpace/kiyoshisasano-DeepZenSpace)  
This repository serves as the public source mirror of the Zenodo-archived version.

---

## Contact

**Author:** Kiyoshi Sasano  
ğŸ“§ Contact via GitHub Discussions or Issues  
ğŸŒ DOI: [10.5281/zenodo.17336217](https://doi.org/10.5281/zenodo.17336217)
