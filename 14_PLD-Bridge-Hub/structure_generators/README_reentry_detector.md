# ğŸ”„ Reentry Detector â€” PLD-Based Intent Resumption Analysis

This module detects **reentry** in user input â€” when a user implicitly returns to a previously dropped or delayed topic.  
It is part of the **Phase Loop Dynamics (PLD)** toolkit, modeling interaction as cycles of **drift**, **repair**, and **reentry**.

---

## âš™ï¸ Functionality

Given a list of prior conversation segments and a current user input, this bot evaluates whether the new input constitutes a **reentry** â€” reconnecting with a past latent intent.

**PLD Concept Mapping**:  
| Code Element       | PLD Theory               |
|--------------------|--------------------------|
| `past_segments`    | Latent phase history     |
| `current_input`    | Recombination attempt    |
| `matching_segment` | Anchored reentry point   |

---

## ğŸ§  Theoretical Basis

ğŸ“˜ **Phase Loop Dynamics (PLD)** defines reentry as a return to a previously activated latent structure  
that may have been interrupted, delayed, or repaired.

- From Paper #1: *Reentry as loopwise resonance with initial semantic state*
- From Paper #2: *Segment â†’ Delay â†’ Recombination* model of dialogue

---

## ğŸ’¡ How It Works

1. You pass in a list of `past_segments` (chronologically ordered).
2. Provide the `current_input` â€” the userâ€™s latest message.
3. The LLM determines whether the new input reconnects with a past intent.
4. It returns:
   - `is_reentry` â€” whether reentry occurred
   - `reason` â€” explanation from the LLM
   - `matching_segment` â€” the past input it relates to (if any)

---

## ğŸ§ª Usage Example

```python
from reentry_detector import detect_reentry

past = [
    "How do I export this as PDF?",
    "Wait, what does 'latency hold' mean again?",
    "Can I try this on mobile?"
]
new_input = "Actually, about the latency thing... is that why it paused?"

result = detect_reentry(past, new_input)
print(result)
```

ğŸŒ€ Expected Output:

```json
{
  "is_reentry": true,
  "reason": "Yes â€” the input resumes the user's previous question about latency hold.",
  "matching_segment": "Wait, what does 'latency hold' mean again?"
}
```

---

### ğŸ” Edge Case Testing (English Version)

```python
# Partial match
detect_reentry(["Trip to Tokyo"], "About that Tokyo thing...")

# Irrelevant input
detect_reentry(["I want to make a reservation"], "Totally unrelated, but...")
```

ğŸ§¾ Sample Output:

```json
{
  "is_reentry": true,
  "reason": "Yes â€” user resumes a previously mentioned topic: Tokyo trip.",
  "matching_segment": "Trip to Tokyo"
}
```

```json
{
  "is_reentry": false,
  "reason": "The current input is unrelated to any prior segment.",
  "matching_segment": ""
}
```

---

## ğŸ›ï¸ Configuration Notes

- **API Key:** Requires setting the OpenAI API key via environment variable:

```bash
export OPENAI_API_KEY="sk-..."  # (Linux/macOS)
set OPENAI_API_KEY="sk-..."     # (Windows)
```

- **Temperature Parameter:**  
  Default is `0.3`, to balance:
  - âœ³ï¸ Consistency (low randomness)  
  - âœ³ï¸ Nuanced pattern detection  

---

## ğŸ“š Related Resources

- ğŸ“˜ PLD Theories â€” [`docs/zenodo_paper_links.md`](../docs/zenodo_paper_links.md)  
- ğŸ“Š Generator Index â€” [`structure_generators/README_structure_generators.md`](../structure_generators/README_structure_generators.md)  
- ğŸ§© Notion Template â€” [`notion_ui_templates/README_notion_ui_templates.md`](../notion_ui_templates/README_notion_ui_templates.md)  

---

## ğŸ“œ License

**License:** Creative Commons BY-NC 4.0  
Structural reuse requires **attunement**, not extraction.  
Drift-aware contributions are preferred over speed or optimization.
