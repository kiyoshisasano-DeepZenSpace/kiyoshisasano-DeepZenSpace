# PLD â€” High-Level Summary

> A runtime governance model for stabilizing multi-turn LLM agents â€” bridging conceptual design, implementation patterns, evaluation signals, and operational practice.

---

# Repository Summary

> High-level architecture and lifecycle overview of PLD.

<img src="./SUMMARY.svg" width="100%" />

---

## 1. Why PLD Exists

Multi-turn LLM agents donâ€™t usually fail because they lack capability â€”  
they fail because behavior **drifts over time**.

Without runtime governance, agents develop:

- cascading tool failures
- self-contradiction and hallucinated context
- memory drift or task forgetting
- unstable reasoning loops
- silent misalignment with user intent

PLD introduces a structured runtime loop that detects misalignment early, repairs behavior, and confirms recovery before continuing.

```
Drift â†’ Repair â†’ Reentry â†’ Continue â†’ Outcome
```

---

## 2. What PLD Is (and Is Not)

PLD is:

- a **runtime phase model** for maintaining alignment over multiple turns  
- a structured method for drift detection, repair, and confirmation  
- **observable and measurable**, designed to integrate with telemetry and evaluation  
- framework-agnostic: compatible with tool agents, RAG systems, memory-enabled agents, and planners  

PLD is **not**:

- a prompt template  
- a single API or product  
- a fixed implementation  
- a one-shot evaluation method  

Rather, PLD provides a **governance layer**, not architectural lock-in.

---

## 3. Who Uses PLD

| Role | Value |
|------|-------|
| LLM / Agent Engineers | Fewer cascading failures and forced resets |
| UX Designers | Predictable repair and confirmation patterns |
| AgentOps / Eval Teams | Observable, comparable, repeatable behavior diagnostics |
| Research / Applied ML | A structured way to study alignment dynamics over time |

---

## 4. The Runtime Loop

| Phase | Purpose | Common Signals |
|-------|---------|----------------|
| **Drift** | Detect divergence from task or shared state | invalid tool use, contradiction, missing constraints |
| **Repair** | Apply a correction (soft or hard) | clarification, reset, constraint restatement |
| **Reentry** | Confirm alignment is successfully restored | checkpoint summary, task restatement |
| **Continue** | Resume task execution | next valid action or response |
| **Outcome** | Resolve the interaction | success / partial / failure / abandoned |

> Compatible with LangGraph, Assistants API, AutoGen, Swarm, Rasa, ReAct-style planners, and custom orchestrators.

---

## 5. Repository Architecture â€” How to Read This Repo

The repository is organized into five main areas:

```
/quickstart â€” Learning path + implementation patterns (start here)
/pld_runtime â€” Reference implementation (optional)
/docs â€” Conceptual model, taxonomy, diagrams, definitions
/analytics â€” Benchmarks, evaluation traces, case studies
/field â€” Adoption methodology and collaboration structure
```


A concise map:

| Layer | Role |
|-------|------|
| Concept Model | `/docs` |
| Implementation Patterns | `/quickstart` |
| Optional Runtime Reference | `/pld_runtime` |
| Evidence & Evaluation | `/analytics` |
| Organizational Adoption | `/field` |

---

## 6. How to Adopt PLD (Implementation Flow)

A recommended onboarding path:

1. Understand the runtime loop â†’ `/quickstart/overview/`

1.5 Run the teaching runtime (first contact) â†’ `quickstart/hello_pld_runtime.py`  
    â†’ Experience: **Drift â†’ Repair â†’ Reentry â†’ Continue**

1.75 Run the real runtime engine â†’ `quickstart/run_minimal_engine.py`  
     â†’ Verify: ingestion, controller logic, and enforcement policies

2. Apply drift/repair/reentry primitives â†’ `/quickstart/operator_primitives/`

3. Use modular patterns â†’ `/quickstart/patterns/`

4. Run runnable integration recipes â†’ `/quickstart/patterns/04_integration_recipes/`  
ã€€ - Optional: `failover_recipe.md` â€” bounded retry + controlled failover  
ã€€ã€€ (recommended after mastering core loop)

5. Log drift â†’ repair â†’ reentry â†’ outcome signals â†’ `/quickstart/metrics/`

6. Compare runtime behavior against evaluated traces â†’ `/analytics/`

7. Apply operational metrics for tuning and release gating â†’  
   `/docs/07_pld_operational_metrics_cookbook.md`  
ã€€ â†’ Measure: **PRDR (stability) Â· REI (cost-effectiveness) Â· VRL (visible repair load)**

---

This onboarding path bridges:

> **Concept â†’ Interaction â†’ Implementation â†’ Observability â†’ Evaluation â†’ Operationalization**

---

## 7. Supporting Layers

### Runtime Reference

`pld_runtime` is not required â€” it serves as a reference implementation demonstrating how the semantics of PLD map to real systems.

### Metrics as Control Signals

Metrics are not merely post-hoc evaluation.  
They also act as **runtime decision inputs**, including:

- phase transitions  
- confidence thresholds  
- fallback and retry gating  
- repair success validation  

ðŸ“Œ Metrics = evaluation + real-time observability + control.

### Evidence Layer

`analytics` provides the empirical backbone validating PLD across:

- MultiWOZ 2.4 (200 annotated dialogs)
- tool-enabled agent traces
- applied SaaS support case study
- field PoC deployments

---

## 8. One-Sentence Definition

> PLD is a runtime governance framework that stabilizes multi-turn LLM agents through structured drift detection, repair, and reentry â€” bridging conceptual design and operational practice.

---

Maintainer: **Kiyoshi Sasano**  
License: **CC BY 4.0 (commercial use requires written permission)**


