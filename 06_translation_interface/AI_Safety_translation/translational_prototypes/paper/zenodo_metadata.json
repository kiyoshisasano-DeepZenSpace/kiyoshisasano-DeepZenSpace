{
  "metadata": {
    "title": "Calibrated Transparency: A Mechanistic, Adversarial-Robust, and Policy-Aligned Safety Architecture",
    "upload_type": "publication",
    "publication_type": "article",
    "description": "I propose **Calibrated Transparency (CT)**, a formal framework that integrates recursive value learning, adversarial-robust verification, and cryptographic auditability to operationalize AI safety governance. Unlike descriptive transparency, CT establishes **causal pathways** from calibration mechanisms to safety guarantees through: (i) state-consistent Lyapunov verification with runtime monitoring, (ii) robustness against metric gaming and deceptive alignment with measurable detection bounds, (iii) **operationally defined metrics** with reproducible protocols, and (iv) policy-aligned implementation mappings. I synthesize 2020–2025 research across preference learning (Kim et al., 2025), Lyapunov and barrier-certificate verification (Henzinger et al., 2025), cryptographic auditing (Balan et al., 2025), and governance frameworks (NIST AI RMF, EU AI Act, ISO/IEC 42001). Our core contribution is a mechanistically grounded theory with dependency-aware risk composition, demonstrating that transparent calibration—when coupled with adversarial stress-testing and formal barrier certificates—provides measurable operational assurance against known failure modes (hallucination, specification gaming, oversight collapse), while explicitly acknowledging limitations for existential-risk scenarios.",
    "creators": [
      {
        "name": "Sasano, Kiyoshi"
      }
    ],
    "license": "CC-BY-4.0",
    "doi": "10.5281/zenodo.17336217",
    "keywords": [
      "AI Safety",
      "Mechanistic Interpretability",
      "Alignment",
      "Governance",
      "Lyapunov Verification",
      "Cryptographic Audit",
      "Risk Management"
    ],
    "access_right": "open",
    "publication_date": "2025-10-13",
    "related_identifiers": [
      {
        "relation": "isSupplementTo",
        "identifier": "https://github.com/kiyoshisasano-DeepZenSpace/kiyoshisasano-DeepZenSpace",
        "scheme": "url"
      }
    ],
    "communities": [
      {
        "identifier": "artificial-intelligence"
      },
      {
        "identifier": "ai-safety"
      },
      {
        "identifier": "machine-learning"
      }
    ]
  }
}
